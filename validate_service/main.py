# from fastapi import FastAPI, UploadFile, File, HTTPException
# from fastapi.middleware.cors import CORSMiddleware
# from transformers import CLIPProcessor, CLIPModel
# from PIL import Image
# import torch
# import io
#
# app = FastAPI(title="TryOnX AI Validate Service")
#
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )
#
# # 1. ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ ë¡œë“œ)
# # "openai/clip-vit-base-patch32"ëŠ” ì„±ëŠ¥ê³¼ ì†ë„ì˜ ê· í˜•ì´ ì¢‹ì€ ëª¨ë¸ì…ë‹ˆë‹¤.
# MODEL_ID = "openai/clip-vit-base-patch32"
# print(f"Loading AI Model: {MODEL_ID}...")
# device = "cuda" if torch.cuda.is_available() else "cpu"
# model = CLIPModel.from_pretrained(MODEL_ID).to(device)
# processor = CLIPProcessor.from_pretrained(MODEL_ID)
# print("Model loaded successfully.")
#
# # 2. ê²€ì¦í•  ì¹´í…Œê³ ë¦¬ ì •ì˜ (í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸)
# # ì˜ìƒì¸ì§€ ì•„ë‹Œì§€ë¥¼ íŒë³„í•˜ê¸° ìœ„í•œ ê¸°ì¤€ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
# LABELS = [
#     "a photo of a clothing garment",   # ì˜ìƒ (ì…”ì¸ , ë°”ì§€, ì›í”¼ìŠ¤ ë“±)
#     "a photo of a human face",         # ì–¼êµ´ (í”¼íŒ… ë¶€ì í•©)
#     "a photo of a naked body part",    # ê³¼ë„í•œ ë…¸ì¶œ (í”¼íŒ… ë¶€ì í•©)
#     "a complex background with no object", # ë°°ê²½ë§Œ ìˆëŠ” ê²½ìš°
#     "text or document"                 # í…ìŠ¤íŠ¸/ë¬¸ì„œ
# ]
#
# @app.get("/")
# async def root():
#     return {"status": "ok", "model": MODEL_ID, "device": device}
#
# @app.post("/validate")
# async def validate(image: UploadFile = File(...)):
#     """
#     CLIP ëª¨ë¸ ê¸°ë°˜ ì´ë¯¸ì§€ ê²€ì¦
#     - ì´ë¯¸ì§€ê°€ 'ì˜ìƒ(clothing)' í…ìŠ¤íŠ¸ì™€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ í™•ë¥  ê³„ì‚°
#     """
#     try:
#         # ì´ë¯¸ì§€ ì½ê¸°
#         contents = await image.read()
#         if len(contents) == 0:
#             return {"isClothing": False, "confidence": 0.0}
#
#         pil_image = Image.open(io.BytesIO(contents)).convert("RGB")
#
#         # ì „ì²˜ë¦¬ ë° ëª¨ë¸ ì¶”ë¡ 
#         inputs = processor(
#             text=LABELS,
#             images=pil_image,
#             return_tensors="pt",
#             padding=True
#         ).to(device)
#
#         with torch.no_grad():
#             outputs = model(**inputs)
#
#         # í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìœ ì‚¬ë„ ì ìˆ˜ (Logits) -> í™•ë¥ (Softmax) ë³€í™˜
#         logits_per_image = outputs.logits_per_image
#         probs = logits_per_image.softmax(dim=1) # ì˜ˆ: [[0.85, 0.10, 0.02, ...]]
#
#         # ê²°ê³¼ í•´ì„
#         # LABELS[0] ("a photo of a clothing garment")ì˜ í™•ë¥  ê°€ì ¸ì˜¤ê¸°
#         clothing_score = probs[0][0].item()
#
#         # ì–¼êµ´ì´ë‚˜ ë…¸ì¶œ ë“± ë¶€ì •ì  ìš”ì†Œì˜ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ì§€ í™•ì¸
#         # (clothing ì ìˆ˜ê°€ 1ë“±ì´ì–´ì•¼ í•¨)
#         max_idx = probs.argmax().item()
#         is_clothing_top_rank = (max_idx == 0)
#
#         # ê²°ì • ë¡œì§
#         # 1) ì˜ìƒì¼ í™•ë¥ ì´ ê°€ì¥ ë†’ì•„ì•¼ í•¨ (is_clothing_top_rank)
#         # 2) ê·¸ í™•ë¥ ì´ ìµœì†Œ 0.6 (60%) ì´ìƒì´ì–´ì•¼ í•¨
#         threshold = 0.6
#         is_valid = is_clothing_top_rank and (clothing_score > threshold)
#
#         return {
#             "isClothing": is_valid,
#             "confidence": round(clothing_score, 4),
#             "details": {
#                 "top_prediction": LABELS[max_idx],
#                 "scores": {label: round(probs[0][i].item(), 4) for i, label in enumerate(LABELS)}
#             }
#         }
#
#     except Exception as e:
#         print(f"Validation Error: {str(e)}")
#         raise HTTPException(status_code=500, detail="Model inference failed")

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from transformers import CLIPProcessor, CLIPModel
from PIL import Image
import torch
import io

app = FastAPI(title="TryOnX AI Validate Service")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

MODEL_ID = "openai/clip-vit-base-patch32"
print(f"Loading AI Model: {MODEL_ID}...")
device = "cuda" if torch.cuda.is_available() else "cpu"
model = CLIPModel.from_pretrained(MODEL_ID).to(device)
processor = CLIPProcessor.from_pretrained(MODEL_ID)
print("Model loaded successfully.")

# ==========================================
# [í•µì‹¬ ìˆ˜ì • 1] ë¼ë²¨ ì •ì˜ë¥¼ ì •êµí•˜ê²Œ ë³€ê²½
# ==========================================
LABELS = [
    "a photo of a standalone clothing garment without person",  # 0ë²ˆ: ì˜ìƒ ë‹¨ë… (ì •ë‹µ)
    "a photo of a person wearing clothes",                    # 1ë²ˆ: ì˜· ì…ì€ ì‚¬ëŒ (íƒˆë½)
    "a photo of a human face or selfie",                      # 2ë²ˆ: ì–¼êµ´/ì…€ì¹´ (íƒˆë½)
    "an anime or cartoon character",                          # 3ë²ˆ: ìºë¦­í„° (íƒˆë½)
    "a photo of a naked body part",                           # 4ë²ˆ: ë…¸ì¶œ (íƒˆë½)
    "text or document or blurry background"                   # 5ë²ˆ: ê¸°íƒ€ ì¡ìŒ (íƒˆë½)
]

@app.get("/")
async def root():
    return {"status": "ok", "model": MODEL_ID}

@app.post("/validate")
async def validate(image: UploadFile = File(...)):
    try:
        contents = await image.read()
        if len(contents) == 0:
            return {"isClothing": False, "confidence": 0.0}

        pil_image = Image.open(io.BytesIO(contents)).convert("RGB")

        inputs = processor(
            text=LABELS,
            images=pil_image,
            return_tensors="pt",
            padding=True
        ).to(device)

        with torch.no_grad():
            outputs = model(**inputs)

        logits_per_image = outputs.logits_per_image
        probs = logits_per_image.softmax(dim=1)

        # ê° í•­ëª©ë³„ í™•ë¥  ì¶”ì¶œ
        scores = {label: round(probs[0][i].item(), 4) for i, label in enumerate(LABELS)}

        # 0ë²ˆ(ì •ë‹µ) ì ìˆ˜
        clothing_score = probs[0][0].item()

        # 1ë“±ì´ ëˆ„êµ¬ì¸ì§€ í™•ì¸
        max_idx = probs.argmax().item()

        # ==========================================
        # [í•µì‹¬ ìˆ˜ì • 2] ê²€ì¦ ë¡œì§ ê°•í™”
        # ==========================================
        # ì¡°ê±´ 1: ê°€ì¥ ë†’ì€ í™•ë¥ ì´ 0ë²ˆ(ë‹¨ë… ì˜ìƒ)ì´ì–´ì•¼ í•¨
        is_top_rank = (max_idx == 0)

        # ì¡°ê±´ 2: 'ì˜· ì…ì€ ì‚¬ëŒ'ì¼ í™•ë¥ ì´ ë„ˆë¬´ ë†’ìœ¼ë©´ ì•ˆ ë¨ (ì´ì¤‘ ì²´í¬)
        # ì˜ˆ: ë‹¨ë… ì˜ìƒ 45%, ì˜· ì…ì€ ì‚¬ëŒ 40% -> ì´ëŸ° ì• ë§¤í•œ ê²½ìš°ë¥¼ ê±°ë¥´ê¸° ìœ„í•¨
        person_score = probs[0][1].item() # ì˜· ì…ì€ ì‚¬ëŒ ì ìˆ˜
        character_score = probs[0][3].item() # ìºë¦­í„° ì ìˆ˜

        # "ì‚¬ëŒ"ì´ë‚˜ "ìºë¦­í„°"ì¼ í™•ë¥ ì´ 20%ë¥¼ ë„˜ìœ¼ë©´ ìœ„í—˜êµ°ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ íƒˆë½ì‹œí‚¬ ìˆ˜ë„ ìˆìŒ
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ 1ë“±ì´ ì•„ë‹ˆë©´ íƒˆë½, ê·¸ë¦¬ê³  ì •ë‹µ ì ìˆ˜ê°€ 0.5(50%) ì´ìƒì´ì–´ì•¼ í•¨ìœ¼ë¡œ ì„¤ì •
        threshold = 0.5

        # ìµœì¢… íŒë‹¨: 1ë“±ì´ 'ë‹¨ë… ì˜ìƒ'ì´ê³ , ì ìˆ˜ê°€ ì„ê³„ê°’ì„ ë„˜ì–´ì•¼ í•¨
        is_valid = is_top_rank and (clothing_score > threshold)

        # ë¡œê·¸ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        print(f"ğŸ” ë¶„ì„: {LABELS[max_idx]} ({round(probs[0][max_idx].item(), 2)})")
        if not is_valid:
             print(f"   âŒ íƒˆë½ ì‚¬ìœ : 1ë“± ì•„ë‹˜ í˜¹ì€ ì ìˆ˜ ë¯¸ë‹¬ (ì˜ìƒì ìˆ˜: {clothing_score:.2f}, ì‚¬ëŒì ìˆ˜: {person_score:.2f})")

        return {
            "isClothing": is_valid,
            "confidence": round(clothing_score, 4),
            "details": {
                "top_prediction": LABELS[max_idx],
                "scores": scores
            }
        }

    except Exception as e:
        print(f"Validation Error: {str(e)}")
        raise HTTPException(status_code=500, detail="Model inference failed")
